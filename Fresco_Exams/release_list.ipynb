{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note : Dont Change the order of cells or add cells in between the cells in this notebook If you want to do rough works feel free to open a new python3 jupyter notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import All necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "from hashlib import md5\n",
    "import pickle\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Read the avocado.csv file to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Date Gender Race  Age_at_Booking  Current_Age\n",
       "0  2015-09-01      M    W              28           29\n",
       "1  2015-09-01      M    B              22           22\n",
       "2  2015-09-01      M    W              37           37\n",
       "3  2015-09-01      M    B              33           34\n",
       "4  2015-09-01      M    B              22           24"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Gender</th>\n      <th>Race</th>\n      <th>Age_at_Booking</th>\n      <th>Current_Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>W</td>\n      <td>28</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>B</td>\n      <td>22</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>W</td>\n      <td>37</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>B</td>\n      <td>33</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>B</td>\n      <td>22</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv('crimedata.csv', delimiter = ',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Find the mean of 'Total Volume' from 29 NOV 2015 to 13 april 2018 of Boston 'region'. Round off the output to 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Date Gender Race  Age_at_Booking  Current_Age  DeltaAge\n",
       "349  2015-09-01      M    B              47           58        11\n",
       "2300 2015-09-01      M    B              19           24         5\n",
       "2781 2015-09-02      M    B              47           58        11\n",
       "4709 2015-09-02      M    B              19           24         5\n",
       "5175 2015-09-03      M    B              47           58        11"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Gender</th>\n      <th>Race</th>\n      <th>Age_at_Booking</th>\n      <th>Current_Age</th>\n      <th>DeltaAge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>349</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>B</td>\n      <td>47</td>\n      <td>58</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2300</th>\n      <td>2015-09-01</td>\n      <td>M</td>\n      <td>B</td>\n      <td>19</td>\n      <td>24</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2781</th>\n      <td>2015-09-02</td>\n      <td>M</td>\n      <td>B</td>\n      <td>47</td>\n      <td>58</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4709</th>\n      <td>2015-09-02</td>\n      <td>M</td>\n      <td>B</td>\n      <td>19</td>\n      <td>24</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5175</th>\n      <td>2015-09-03</td>\n      <td>M</td>\n      <td>B</td>\n      <td>47</td>\n      <td>58</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df1 = df[df['Race']=='B']\n",
    "df1['DeltaAge'] = df1['Current_Age']-df1['Age_at_Booking']\n",
    "df2 = df1[df1['DeltaAge'] >= 5]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2)\n",
    "from pandas.io.parquet import to_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-73a1622f27b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'release_list.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.msvscode.hdinsight\\hdinsightJupyter\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.msvscode.hdinsight\\hdinsightJupyter\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m   2363\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2365\u001b[1;33m         to_parquet(\n\u001b[0m\u001b[0;32m   2366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2367\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.msvscode.hdinsight\\hdinsightJupyter\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mpartition_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m     return impl.write(\n\u001b[0;32m    271\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.msvscode.hdinsight\\hdinsightJupyter\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n - \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;34m\"Unable to find a usable engine; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "df2.to_parquet('release_list.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295854.27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "start_date = '2015-11-29'\n",
    "end_date = '2018-04-13'\n",
    "mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "df1 = df.loc[mask]\n",
    "df1 = df1[df1['region']=='Boston']\n",
    "df1_mean = df1[\"Total Volume\"].mean()\n",
    "df1_mean.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Find the median of 'Total Bags' from 29 NOV 2015 to 13 april 2018 of Boston 'region'.Round off the output to 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49575.64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_median = df1[\"Total Bags\"].median()\n",
    "df1_median.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Find the mode of 'AveragePrice' from 29 NOV 2015 to 13 april 2018 of Boston 'region'.Round off the output to 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.59\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_mode = df1[\"AveragePrice\"].mode()\n",
    "df1_mode.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Find the standard deviation of 'AveragePrice' from 29 NOV 2015 to 13 april 2018 of Boston 'region'.Round off the output to 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_std = df1[\"AveragePrice\"].std()\n",
    "df1_std.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Find the variance of 'AveragePrice' from 29 Nov 2015 to 13 april 2018 of Boston 'region'.Round off the output to 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_var = df1[\"AveragePrice\"].var()\n",
    "df1_var.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the below cells to save your answers in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickle(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geth(obj):\n",
    "    obj = str(obj).encode()\n",
    "    m = hashlib.md5()\n",
    "    m.update( bytes(obj) )\n",
    "    #print(m.hexdigest())\n",
    "\n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pickle(file_name, obj):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(geth(obj), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fea33cd18278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpickling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-fea33cd18278>\u001b[0m in \u001b[0;36mpickling\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpickling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmake_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q1.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmake_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q2.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmake_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q3.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmake_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q4.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a1' is not defined"
     ]
    }
   ],
   "source": [
    "def pickling():\n",
    "    make_pickle('q1.pickle', a1)\n",
    "    make_pickle('q2.pickle', a2)\n",
    "    make_pickle('q3.pickle', a3)\n",
    "    make_pickle('q4.pickle', a4)\n",
    "    make_pickle('q5.pickle', a5)\n",
    "   \n",
    "    \n",
    "pickling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}